{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def average_lists_numpy(*lists):\n",
    "    # 将所有列表转换为 NumPy 数组\n",
    "    arrays = [np.array(l) for l in lists]\n",
    "    \n",
    "    # 沿着新轴（axis=0）计算平均值\n",
    "    return np.mean(arrays, axis=0)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_two_lists(list1, list2, title1=\"Mean\", title2=\"Variance\"):\n",
    "    # 创建两个子图\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 10))\n",
    "    \n",
    "    # 绘制第一个列表的折线图\n",
    "    ax1.plot(list1, marker='o')\n",
    "    ax1.set_title(title1)\n",
    "    ax1.set_xlabel('Index')\n",
    "    ax1.set_ylabel('Value')\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    # 绘制第二个列表的折线图\n",
    "    ax2.plot(list2, marker='o', color='red')\n",
    "    ax2.set_title(title2)\n",
    "    ax2.set_xlabel('Index')\n",
    "    ax2.set_ylabel('Value')\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    # 调整子图之间的间距\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # 显示图形\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# average = average_lists_numpy(ist1, list2, list3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 80\u001b[0m\n\u001b[1;32m     76\u001b[0m     theta_Rhos_across_times\u001b[38;5;241m.\u001b[39mappend(theta_Rhoi)\n\u001b[1;32m     77\u001b[0m     pts_indices_across_times\u001b[38;5;241m.\u001b[39mappend(pts_indicei)\n\u001b[0;32m---> 80\u001b[0m matched_theta_Rho_across_times, common_indices \u001b[38;5;241m=\u001b[39m \u001b[43mget_match_pairs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtheta_Rhos_across_times\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpts_indices_across_times\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m points_num \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(common_indices)\n\u001b[1;32m     82\u001b[0m points_num\n",
      "Cell \u001b[0;32mIn[3], line 51\u001b[0m, in \u001b[0;36mget_match_pairs\u001b[0;34m(theta_Rhos_across_times, pts_indices_across_times)\u001b[0m\n\u001b[1;32m     49\u001b[0m matched_theta_Rho_across_times \u001b[38;5;241m=\u001b[39m [] \n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pts_indicei, theta_Rhoi \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(pts_indices_across_times, theta_Rhos_across_times):\n\u001b[0;32m---> 51\u001b[0m     matched_theta_Rho_i \u001b[38;5;241m=\u001b[39m theta_Rhoi[[np\u001b[38;5;241m.\u001b[39mwhere(pts_indicei \u001b[38;5;241m==\u001b[39m idx)[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m common_indices]]\n\u001b[1;32m     52\u001b[0m     matched_theta_Rho_across_times\u001b[38;5;241m.\u001b[39mappend(matched_theta_Rho_i)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m matched_theta_Rho_across_times, common_indices\n",
      "Cell \u001b[0;32mIn[3], line 51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m matched_theta_Rho_across_times \u001b[38;5;241m=\u001b[39m [] \n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pts_indicei, theta_Rhoi \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(pts_indices_across_times, theta_Rhos_across_times):\n\u001b[0;32m---> 51\u001b[0m     matched_theta_Rho_i \u001b[38;5;241m=\u001b[39m theta_Rhoi[[np\u001b[38;5;241m.\u001b[39mwhere(\u001b[43mpts_indicei\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m)[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m common_indices]]\n\u001b[1;32m     52\u001b[0m     matched_theta_Rho_across_times\u001b[38;5;241m.\u001b[39mappend(matched_theta_Rho_i)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m matched_theta_Rho_across_times, common_indices\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python3\n",
    "import numpy as np\n",
    "import transforms3d\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import sys\n",
    "import csv\n",
    "import os\n",
    "\n",
    "from matplotlib import cm\n",
    "\n",
    "# Append the root dir\n",
    "import sys, roslib, os\n",
    "lias_anp_dir = roslib.packages.get_pkg_dir('lias_anp')\n",
    "scripts_dir = os.path.abspath(os.path.join(lias_anp_dir, 'scripts'))\n",
    "sys.path.append(scripts_dir)\n",
    "from utils.sonar_data_processor import SonarDataReader\n",
    "from utils.match_pairs import get_match_pairs\n",
    "from anp.anp_alg import AnPAlgorithm\n",
    "from tri.tri import ANRS, GTRS, gradient_descent\n",
    "from utils.pose2matrix import pose_to_transform_matrix, ros_pose_to_transform_matrix, transform_matrix_to_ros_pose\n",
    "from utils.coordinate_system_transform import coordinate_transform_Pose, coordinate_transform_Pose_back, coordinate_transform_pt, coordinate_transform_pt_back\n",
    "from utils.transformation_matrix_add_noise import add_noise_to_pose\n",
    "\n",
    "import yaml\n",
    "yaml_file_path = os.path.join(lias_anp_dir, 'yaml/odom.yaml')\n",
    "with open(yaml_file_path, 'r') as file:\n",
    "    params = yaml.safe_load(file)\n",
    "    RECONSTRUCTION_ERROR_THRESHOLD = params['RECONSTRUCTION_ERROR_THRESHOLD']\n",
    "    RECORD = params['RECORD']\n",
    "    DATA_PATH = params['data_path']\n",
    "    ANP_METHOD = params['ANP_METHOD']\n",
    "\n",
    "sonar_data_dir = str(lias_anp_dir) + DATA_PATH\n",
    "reord_dir = str(lias_anp_dir) + \"/record/\" + ANP_METHOD\n",
    "reader = SonarDataReader(filepath = sonar_data_dir)\n",
    "reader.read_data()\n",
    "data = reader.get_data()\n",
    "\n",
    "from functools import reduce\n",
    "def intersect_multiple_arrays(array_list):\n",
    "    array_lists = [list(arr) for arr in array_list]\n",
    "    return list(reduce(np.intersect1d, array_lists))\n",
    "\n",
    "def get_match_pairs(theta_Rhos_across_times, pts_indices_across_times):\n",
    "    common_indices = intersect_multiple_arrays(pts_indices_across_times)\n",
    "    matched_theta_Rho_across_times = [] \n",
    "    for pts_indicei, theta_Rhoi in zip(pts_indices_across_times, theta_Rhos_across_times):\n",
    "        matched_theta_Rho_i = theta_Rhoi[[np.where(pts_indicei == idx)[0][0] for idx in common_indices]]\n",
    "        matched_theta_Rho_across_times.append(matched_theta_Rho_i)\n",
    "    return matched_theta_Rho_across_times, common_indices\n",
    "\n",
    "theta_Rhos_across_times = []\n",
    "pts_indices_across_times = []\n",
    "T_tri_accross_times = []\n",
    "\n",
    "\n",
    "# INITIALIZE_FRAMES = 2 # at least 2 frame\n",
    "\n",
    "mean_list = []\n",
    "variance_list = []\n",
    "\n",
    "for experiment_times in range(100):\n",
    "    means = []\n",
    "    variances = []\n",
    "\n",
    "    for INITIALIZE_FRAMES in range(2, 10):\n",
    "        for i in range(INITIALIZE_FRAMES):\n",
    "            Ti_tri = coordinate_transform_Pose(ros_pose_to_transform_matrix(data[i]['pose']))\n",
    "            Ti_tri = add_noise_to_pose(Ti_tri, rotation_noise_std=0.0001, translation_noise_std=0.0001)\n",
    "            theta_Rhoi = data[i]['si_q_theta_Rho']\n",
    "            pts_indicei = data[i]['pts_indice']\n",
    "            T_tri_accross_times.append(Ti_tri)\n",
    "            theta_Rhos_across_times.append(theta_Rhoi)\n",
    "            pts_indices_across_times.append(pts_indicei)\n",
    "\n",
    "            \n",
    "        matched_theta_Rho_across_times, common_indices = get_match_pairs(theta_Rhos_across_times, pts_indices_across_times)\n",
    "        points_num = len(common_indices)\n",
    "        points_num\n",
    "        # Now we have T_tri_accross_times and matched_theta_Rho_across_times\n",
    "\n",
    "        # We need to iterate through points\n",
    "        matched_theta_Rho_across_times = np.array(matched_theta_Rho_across_times)\n",
    "\n",
    "        ############################################################\n",
    "        ## find gt ##\n",
    "        theta_Rho0 = data[0]['si_q_theta_Rho']\n",
    "        pts_indice0 = data[0]['pts_indice']\n",
    "        w_P_gt = data[0]['w_p']\n",
    "        w_P_gt_indices = [np.where(pts_indice0 == idx)[0][0] for idx in common_indices]\n",
    "        w_P_gt = w_P_gt[w_P_gt_indices] \n",
    "        ############################################################\n",
    "\n",
    "        # for each points\n",
    "        record = []\n",
    "        for point_index in range(points_num):\n",
    "            theta_Rhos = matched_theta_Rho_across_times[:,point_index,:]\n",
    "            \n",
    "            A_stacked = np.empty((0, 4))\n",
    "            b_stacked = np.empty((0,))\n",
    "            A_list = []\n",
    "            b_list = []\n",
    "\n",
    "            for i in range(INITIALIZE_FRAMES-1):\n",
    "                T0 = T_tri_accross_times[i]\n",
    "                T1 = T_tri_accross_times[i+1]\n",
    "                T_matrix = np.linalg.inv(T1) @ T0\n",
    "                theta_Rho = theta_Rhos[i]\n",
    "                theta_Rho_prime = theta_Rhos[i+1]\n",
    "            \n",
    "                \n",
    "                ##################################################### \n",
    "                # print(\"~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "                # s_P_cmp, least_square = ANRS(T_matrix, theta_Rho, theta_Rho_prime)\n",
    "                # # Transform back to sim coordinate system\n",
    "                # w_P_cmp = ( T0 @ np.hstack([s_P_cmp, 1]) )[:3]\n",
    "                # # w_P_cmp = coordinate_transform_pt_back( w_P_cmp )\n",
    "                # print(\"~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "                ##################################################### \n",
    "                \n",
    "                # 将线性方程组写成矩阵形式 A @ P = B\n",
    "                R_matrix = T_matrix[:3, :3]\n",
    "                t = T_matrix[:3, 3]\n",
    "                r1 = R_matrix[0, :]\n",
    "                r2 = R_matrix[1, :]\n",
    "\n",
    "                # for theta_Rho, theta_Rho_prime in zip(theta_Rhos, theta_Rho_primes):\n",
    "                theta = -theta_Rho[0]\n",
    "                theta_prime = -theta_Rho_prime[0]\n",
    "                R = theta_Rho[1]  # example value for R\n",
    "                R_prime = theta_Rho_prime[1] # example value for R'\n",
    "                \n",
    "                a1 = np.array([-1, np.tan(theta), 0])\n",
    "                b1 = 0 \n",
    "                a2 = np.tan(theta_prime) * r2 - r1\n",
    "                b2 = t[0] - np.tan(theta_prime) * t[1]\n",
    "                a3 = t.T @ R_matrix\n",
    "                b3 = (R_prime**2 - R**2 - np.linalg.norm(t)**2) / 2\n",
    "\n",
    "                A = np.vstack([a1, a2, a3])\n",
    "                b = np.array([b1, b2, b3, 1])\n",
    "\n",
    "                H = np.eye(4)\n",
    "                H[:3, :3] = A\n",
    "                A = H\n",
    "                A1 = A @ np.linalg.inv(T0) \n",
    "\n",
    "                \n",
    "                # 将 A 和 b 添加到列表中\n",
    "                A_stacked = np.vstack((A_stacked, A1))\n",
    "                b_stacked = np.append(b_stacked, b)\n",
    "            \n",
    "            w_P, residuals, rank, s = np.linalg.lstsq(A_stacked, b_stacked, rcond=None)\n",
    "            w_P = coordinate_transform_pt_back( w_P[:3] )\n",
    "\n",
    "            difference = np.linalg.norm( w_P - w_P_gt[point_index] )\n",
    "            record.append(difference)\n",
    "\n",
    "\n",
    "        def calculate_mean_variance_numpy(numbers):\n",
    "            arr = np.array(numbers)\n",
    "            return np.mean(arr), np.var(arr)\n",
    "\n",
    "        mean, variance = calculate_mean_variance_numpy(record)\n",
    "\n",
    "        means.append(mean)\n",
    "        variances.append(variance)\n",
    " \n",
    "    mean_list.append(means)\n",
    "    variance_list.append(variances)\n",
    "\n",
    "\n",
    "mean_data = np.mean([np.array(l) for l in mean_list], axis=0)\n",
    "variance_data = np.mean([np.array(l) for l in variance_list], axis=0)\n",
    "    \n",
    "\n",
    "\n",
    "plot_two_lists(mean_data, variance_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
